<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Hank Is Lolo</title>
  
  
  <link href="http://hankislolo.com/atom.xml" rel="self"/>
  
  <link href="http://hankislolo.com/"/>
  <updated>2022-12-21T14:18:05.403Z</updated>
  <id>http://hankislolo.com/</id>
  
  <author>
    <name>Hank</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>RTFM</title>
    <link href="http://hankislolo.com/2022/12/21/RTFM/"/>
    <id>http://hankislolo.com/2022/12/21/RTFM/</id>
    <published>2022-12-21T10:33:30.000Z</published>
    <updated>2022-12-21T14:18:05.403Z</updated>
    
    <content type="html"><![CDATA[<h2 id="rtfm-robust-temporal-feature-magnitude-learning">RTFM: RobustTemporal Feature Magnitude Learning</h2><p>è¯¥ç¯‡æ–‡ç« æ˜¯ä»¥MILä½œä¸ºWS-VADæ¡†æ¶ä¸­æ•ˆæœæœ€å¥½çš„ä¸€ç¯‡ï¼Œç»“åˆäº†å¯¹æ¯”å­¦ä¹ å’Œæ³¨æ„åŠ›æœºåˆ¶ï¼Œåœ¨ç†è®ºå±‚é¢ä¸Šè¯´æ˜äº†MILæ¡†æ¶åº”å½“æ³¨æ„çš„é—®é¢˜ã€‚åœ¨é˜…è¯»è®ºæ–‡çš„è¿‡ç¨‹ä¸­ï¼Œæˆ‘æ€»ç»“å‡ºä»¥ä¸‹é—®é¢˜ï¼Œæ˜¯è¯¥ç¯‡æ–‡ç« å°šæœªè¯´æ˜ç™½æˆ–è€…æˆ‘è¿˜æ²¡æœ‰ç†è§£çš„ã€‚</p><h4 id="å…³äºèšåˆæ–¹æ³•">å…³äºèšåˆæ–¹æ³•</h4><p>2020å¹´æ¥è‡ªæ¾³å¤§åˆ©äºšçš„å›¢é˜Ÿç ”ç©¶çš„ç»“æœè¯æ˜ï¼Œåœ¨è§†é¢‘å¼‚å¸¸æ£€æµ‹ä»»åŠ¡ä¸Šï¼ŒæŠ½å–top-kä¸ªç‰‡æ®µç»„åœ¨é‡‡æ ·æ—¶kçš„é€‰æ‹©ä¼šæ˜æ˜¾å½±å“åˆ°æ¨¡å‹çš„æ”¶æ•›ã€‚åŸå› æ˜¯å¢åŠ æ­£ç¡®çš„ç‰‡æ®µç»„å¯ä»¥å¢åŠ æ¥è‡ªäºåŒ…çš„æœ‰æ•ˆä¿¡æ¯ï¼Œå…·ä½“æ¥è¯´ï¼Œ1)é¿å…å› ä¸ºèšåˆæ—¶é‡‡æ ·è¿‡å°‘é€ æˆä¿¡æ¯æŸå¤± 2)èšåˆé€‰å–çš„ä»£è¡¨ç‰‡æ®µï¼ˆè‹¥é‡‡ç”¨maxä½œä¸ºèšåˆå‡½æ•°ï¼‰é”™è¯¯é€ æˆè¯¯å·®ç´¯ç§¯ã€‚ä½†æ˜¯å¢åŠ kçš„å€¼ä¹Ÿä¼šè®©æ¨¡å‹å¤±æ•ˆï¼ŒåŸå› æ˜¯é‡‡æ ·åˆ°çš„ç‰‡æ®µæ— è®ºæ˜¯æ¥è‡ªäºæ­£åŒ…è¿˜æ˜¯è´ŸåŒ…éƒ½æ˜¯è´Ÿå®ä¾‹ï¼Œæ¨¡å‹ä¹Ÿå°±æ— æ³•åŒºåˆ†äº†ã€‚ä¸ºäº†ä¿è¯æ¨¡å‹èƒ½å¤ŸåŒºåˆ†ä¸¤ç±»é‡‡æ ·ç»“æœï¼Œåº”å½“ä½¿é‡‡æ ·çš„kå€¼å°äºç­‰äºçœŸå®æ­£ç‰‡æ®µæ•°<span class="math inline">\(\mu\)</span>ã€‚ã€é—®é¢˜ï¼š<span class="math inline">\(\mu\)</span>æ˜¯å¦‚ä½•ç¡®å®šçš„ï¼Ÿã€‘</p><h4 id="å¯¹æ¯”å­¦ä¹ çš„è®¾è®¡">å¯¹æ¯”å­¦ä¹ çš„è®¾è®¡</h4><p>å¦å¤–ï¼Œè¯¥ç ”ç©¶é‡‡ç”¨ç‰¹å¾å‘é‡çš„2-èŒƒæ•°æ¥å®šä¹‰â€œfeaturemagnitudeâ€ï¼Œè®¤ä¸ºç»è¿‡encoderç¼–ç ä¹‹åçš„ç‰¹å¾å‘é‡èƒ½å¤Ÿåœ¨2-èŒƒæ•°ä¸Šæœ‰æ¯”è¾ƒå¥½çš„åŒºåˆ†ã€‚ä½œä¸ºæ›¿ä»£ï¼Œå¦‚æœæˆ‘é‡‡ç”¨å…¶ä»–çš„èŒƒæ•°æˆ–è€…åº¦é‡æ–¹æ³•ï¼ˆe.g.Hansdorff Distance,etc,.ï¼‰ä¸ºä»€ä¹ˆä¸å¦‚2-èŒƒæ•°å¥½å‘¢ï¼ˆæ¢ä¸€ä¸ªè·ç¦»åº¦é‡æœ‰æ•ˆæœå—ï¼‰ï¼Ÿåœ¨åŸæ–‡ä¸­çš„æŸå¤±å‡½æ•°çš„é€‰æ‹©ä¸Šï¼Œä»–ä»¬é‡‡ç”¨äº†ç±»ä¼¼äºHingeLossçš„æ–¹æ³•æ¥æœ€å¤§åŒ–+/-åŒ…çš„top-kç‰‡æ®µç»„çš„è·ç¦»ï¼ˆå®šä¹‰äº†ä¸€ä¸ªè¶…å‚marginï¼‰æ¥è¿›è¡Œå¯¹æ¯”å­¦ä¹ ã€‚</p><p>å…³äºè·ç¦»åº¦é‡çš„é€‰æ‹©ï¼Œå¯ä»¥ä½¿ç”¨PCAå¯è§†åŒ–æ¥å¤§è‡´è§‚å¯Ÿæ•°æ®åˆ†å¸ƒçš„ç‰¹ç‚¹ã€‚ç”±äºå¯¹æ¯”å­¦ä¹ æ˜¯æ— ç›‘ç£/å¼±ç›‘ç£çš„ï¼Œä»…ä½¿ç”¨å¯¹æ¯”å­¦ä¹ çš„æ–¹æ³•åº”å½“å¯ä»¥ä½¿ä¸¤ç±»åŒ…åˆ†å¼€ï¼Œä½†ä¸ä¸€å®šèƒ½ä½¿ä¸åŒæ ‡ç­¾çš„ç‰‡æ®µå®ä¾‹åˆ†å¼€ã€‚ã€å°è¯•åœ¨<strong>åŒ…</strong>/<strong>å®ä¾‹</strong>ä¸Šéƒ½åšä¸€ä¸‹å¯è§†åŒ–ï¼Œè§‚å¯Ÿåœ¨ä¸€å®šçš„è®­ç»ƒé˜¶æ®µåï¼Œæ­£/è´Ÿæ ·æœ¬çš„åˆ†å¸ƒæƒ…å†µï¼Œå¡«å…¥ä¸‹è¡¨ã€‘</p><center>åŒ…/ç‰‡æ®µç‰¹å¾åœ¨è®­ç»ƒå‰åçš„åˆ†å¸ƒå˜åŒ–ï¼Œé‡‡ç”¨n_topk=3è¿›è¡Œè®­ç»ƒï¼ˆx10ï¼‰</center><table><thead><tr class="header"><th>3DåŠ¨ä½œç‰¹å¾</th><th>ç¼–ç ç‰¹å¾</th><th>ç¼–ç å™¨åŠå‚æ•°</th><th>è®­ç»ƒè½®æ¬¡</th><th>è·ç¦»åº¦é‡æ–¹æ³•</th></tr></thead><tbody><tr class="odd"><td></td><td></td><td></td><td></td><td></td></tr><tr class="even"><td></td><td></td><td></td><td></td><td></td></tr></tbody></table><h4 id="ç¼–ç å™¨çš„è®¾è®¡">ç¼–ç å™¨çš„è®¾è®¡</h4><p>åŸæ–‡å¯¹ç‰¹å¾çš„å¤„ç†æ¯”CVPR2018çš„baselineè€Œè¨€å¤šäº†å¤šå°ºåº¦ç©ºæ´å·ç§¯ä»¥åŠè‡ªæ³¨æ„åŠ›æ¨¡å—ï¼Œä»¥å»ºæ¨¡è§†é¢‘äº‹ä»¶åœ¨æ—¶é—´ä¸Šçš„ä¸Šä¸‹æ–‡å…³ç³»ã€‚åœ¨æœ€è¿‘çš„ç ”ç©¶ä¸­ï¼Œé‡‡ç”¨ConvLSTMæˆ–è€…ConvTransformerçš„æ–¹æ³•ä¹Ÿå¯ä»¥è¾¾åˆ°ç±»ä¼¼çš„æ•ˆæœï¼Œå°¤å…¶æ˜¯åœ¨3DåŠ¨ä½œç‰¹å¾æ¨¡å‹é”å®šä¸å¯è°ƒçš„åŸºç¡€ä¸Šï¼Œå¦‚æœä¸Šä¸‹æ–‡å…³ç³»éå¸¸é‡è¦ï¼Œåº”è¯¥ä¹Ÿèƒ½workã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒRTFMåœ¨ä¼˜åŒ–è¿‡ç¨‹ä¸­å¹¶ä¸æ˜¯2-stageï¼Œè€Œæ˜¯end-to-endï¼Œç›¸å½“äºè¿›è¡Œäº†å¤šä»»åŠ¡åŒæ—¶ä¼˜åŒ–ã€‚å› æ­¤åç»­è¿˜éœ€è¦ç†è§£ä»–çš„ç‰‡æ®µåˆ†ç±»å™¨çš„å®ç°ä»¥åŠè‡ªæ³¨æ„åŠ›æ¨¡å—æ˜¯å¦‚ä½•å‘æŒ¥ä½œç”¨çš„ã€‚åœ¨æ•´ä¸ªä¼˜åŒ–è¿‡ç¨‹ä¸­ï¼Œå®ä¾‹çš„ç©ºé—´embedingæ˜¯å¦‚ä½•å˜åŒ–çš„ä¹Ÿéœ€è¦å¼„æ˜ç™½ã€‚</p><hr><h4 id="todo">TODOï¼š</h4><ul class="task-list"><li><input type="checkbox" disabled>å†æ¬¡è·‘é€šRTFMä»£ç ï¼Œè¾¾åˆ°å®ƒæ‰€å£°ç§°çš„æ•ˆæœã€‚</li><li><input type="checkbox" disabled>è§£æ„RTFMï¼ŒæŠŠæ¯ä¸€æ­¥è¾“å‡ºçš„å®ä¾‹ç‰‡æ®µæŠ½å–å‡ºæ¥åšPCAå¯è§†åŒ–åˆ†æã€‚</li><li><input type="checkbox" disabled>æ¨¡å—çš„æ›¿ä»£æ€§ğŸ§ªï¼šæ¯ä¸ªæ¨¡å—ç”¨å…¶ä»–çš„ç»„ä»¶å»æ›¿ä»£ï¼Œè§‚å¯Ÿå®éªŒç»“æœæ˜¯ä¸Šå‡è¿˜æ˜¯ä¸‹é™ã€‚</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;rtfm-robust-temporal-feature-magnitude-learning&quot;&gt;RTFM: Robust
Temporal Feature Magnitude Learning&lt;/h2&gt;
&lt;p&gt;è¯¥ç¯‡æ–‡ç« æ˜¯ä»¥MILä½œä¸ºWS-VADæ¡†æ¶ä¸­æ•ˆæœæœ€å¥½çš„ä¸€</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>Experiment Chat with Bot</title>
    <link href="http://hankislolo.com/2022/12/12/Experiment-Chat-with-Bot/"/>
    <id>http://hankislolo.com/2022/12/12/Experiment-Chat-with-Bot/</id>
    <published>2022-12-12T03:40:03.000Z</published>
    <updated>2022-12-21T09:16:40.236Z</updated>
    
    <content type="html"><![CDATA[<p>ä»¥ä¸‹æ˜¯å®éªŒè¿‡ç¨‹ä¸­å‘ç°é—®é¢˜å¹¶ä¸æœºå™¨äºº<a href="https://chat.openai.com/chat">ChatBot</a>è®¨è®ºçš„è¿‡ç¨‹ã€‚è®°å½•å¦‚ä¸‹ä»¥ä¾¿æ€è·¯çš„å¼€æ‹“ï¼š</p><h4 id="å…³äºé¢„æµ‹ä¿¡å·å¼‚å¸¸ä¸º0å’Œ1çš„é—®é¢˜">å…³äºé¢„æµ‹ä¿¡å·å¼‚å¸¸ä¸º0å’Œ1çš„é—®é¢˜</h4><blockquote><p>Q: When I use MIL to tackle video anomaly detection task, I got aweird outcome that all scores of all positive bags and negative bags areclosed to 0. But I expect that positive instances are likely to be 1. Iuse hinge loss as my loss function, and aggregation function is maximum.Can you help analyse it?</p></blockquote><p>A: It sounds like you're running into a problem with your lossfunction and aggregation function. In the case of MIL, the idea is totake a collection of instances (called a bag) and determine whether thebag contains any positive instances. To do this, you typically want touse a loss function that encourages the model to output higher valuesfor bags that contain positive instances and lower values for bags thatdo not contain positive instances.</p><p>The maximum aggregation function, on the other hand, takes themaximum value of all the instances in the bag and uses that as the bag'sfinal output. This can lead to problems when the bag contains bothpositive and negative instances, because the maximum function willalways output the maximum value, regardless of whether it comes from apositive or negative instance.</p><p>To solve this problem, you may want to try using a different lossfunction and aggregation function. For example, you could try using thesum or mean aggregation function, which will take into account all theinstances in the bag, rather than just the maximum value. You could alsotry using a loss function that is better suited to MIL tasks, such asthe binary cross-entropy loss.</p><p>Overall, the specific loss function and aggregation function you usewill depend on the details of your task and the requirements of yourmodel. It's worth experimenting with different combinations to find theone that works best for your problem.</p><h4 id="æŸå¤±å‡½æ•°çš„é€‰æ‹©å’Œä¸ä¸‹é™çš„é—®é¢˜">æŸå¤±å‡½æ•°çš„é€‰æ‹©å’Œä¸ä¸‹é™çš„é—®é¢˜</h4><blockquote><p>Q: I tried BCE loss. However the loss would not decrease. I have noidea what happened.</p></blockquote><p>A: If the loss is not decreasing when using the binary cross-entropy(BCE) loss function, it could be due to a variety of reasons. Somepossible causes include:</p><ul><li>The model may <strong>not be learning at all</strong>, which couldbe due to a poor choice of model architecture, a lack of training data,or incorrect model hyperparameters.</li><li>The model may be <strong>overfitting</strong> to the training data,which can cause the loss to stop decreasing even if the model is stilllearning. This can happen if the model is too complex for the amount oftraining data available, or if the training data is not representativeof the true distribution of the data.</li><li>The <strong>learning rate may be too high</strong>, which can causethe model to oscillate or diverge, instead of converging on a minimumloss value.</li></ul><p>To diagnose the problem, it may be helpful to visualize the lossduring training using a tool like TensorBoard. This can give you abetter idea of what's happening during training, and can help youidentify potential issues with the model or the training process.</p><p>If the loss is not decreasing, you may want to try adjusting the<strong>model architecture</strong>, <strong>the training data</strong>,<strong>the learning rate</strong>, or <strong>otherhyperparameters</strong> to see if that helps the model learn moreeffectively. It's also important to make sure that the training data isrepresentative of the true distribution of the data, as this can affectthe model's ability to generalize to new, unseen examples.</p><h4 id="å¦‚ä½•å‘å¤šç¤ºä¾‹å­¦ä¹ åŠ å…¥å…ˆéªŒçŸ¥è¯†">å¦‚ä½•å‘å¤šç¤ºä¾‹å­¦ä¹ åŠ å…¥å…ˆéªŒçŸ¥è¯†</h4><blockquote><p>Q: I want to add some prior information to the MIL training. Theinput samples are extracted features, and I can compute saliency of eachinstance in a bag. How can I accomplish it?</p></blockquote><p>A: To incorporate prior information into a multiple instance learning(MIL) model, you can try <strong>using a regularization term</strong> inthe loss function that encourages the model to use the prior informationwhen making predictions.</p><p>For example, suppose you have a bag of instances, and you havecomputed the saliency of each instance in the bag. You can then use thissaliency information as a regularization term in the loss function, sothat the model is encouraged to give more weight to instances withhigher saliency when making predictions for the bag.</p><p>To do this, you would need to define a regularization term that takesinto account the saliency of each instance in the bag. For example, youcould define the regularization term as the sum of the saliency valuesof all the instances in the bag, multiplied by a regularization strengthhyperparameter. This would encourage the model to give more weight toinstances with higher saliency, and would help the model use the priorinformation more effectively when making predictions.</p><p>In general, the specific form of the regularization term will dependon the details of your task and the requirements of your model. It'sworth experimenting with different regularization terms to see whatworks best for your problem.</p><h4 id="æ•°æ®å¯è§†åŒ–çš„æŠ€å·§">æ•°æ®å¯è§†åŒ–çš„æŠ€å·§</h4><h5 id="å…³äºå¯è§†åŒ–å·¥å…·">å…³äºå¯è§†åŒ–å·¥å…·</h5><blockquote><p>Q: when I tried to visualize my training data information, I found itextremely complicated to redefinate functions via matplotlib. Any bettermethods to visualize my tensor data which are more handy (for me, eventensorboard is kind of complicated)?</p></blockquote><p>A: If you find it difficult to visualize your data using tools likematplotlib or TensorBoard, there are other options you can try. Forexample, you can use a tool like TensorFlow Playground(https://playground.tensorflow.org/) to interactively visualize andexplore your data. This can be a useful way to get a betterunderstanding of your data, and can help you identify patterns andtrends that may not be immediately obvious.</p><p>Another option is to use a tool like Embedding Projector(https://projector.tensorflow.org/) to visualize high-dimensional datain a lower-dimensional space. This can be particularly useful forvisualizing data that has many features or dimensions, as it can helpyou understand the relationships between different features and identifyclusters or patterns in the data.</p><p>Overall, there are many different tools and techniques you can use tovisualize your data, and the best one for you will depend on thespecific details of your data and the goals of your visualization. It'sworth experimenting with different tools and techniques to see whatworks best for your problem.</p><p>æ³¨ï¼šChatBoxæ‰€è¯´EmbeddingProjectoræ˜¯ä¸€ä¸ªç¦»çº¿çš„å¯è§†åŒ–å·¥å…·ï¼Œéœ€è¦å°†è®­ç»ƒè¿‡ç¨‹ä¸­çš„embeddingè½¬åŒ–æˆTSVæ–‡ä»¶å¹¶ä¸Šä¼ åˆ°ä¸Šè¿°ç½‘ç«™ä¸­ï¼Œè·å–å¯è§†åŒ–çš„å›¾åƒã€‚</p><p>è¦å°†å®éªŒæ•°æ®å¯è§†åŒ–ï¼Œé¦–å…ˆç¡®å®šè¦ç ”ç©¶ä»€ä¹ˆç»Ÿè®¡é‡ï¼Œæœ€å°å•å…ƒæ˜¯ä»€ä¹ˆã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­çš„æŸå¤±å˜åŒ–è¿˜æ˜¯ä½¿ç”¨tensorboardæ¯”è¾ƒåˆé€‚ï¼Œä½†æ˜¯å…¶ä»–çš„å˜é‡å¯ä»¥ç”¨å¯è§†åŒ–å·¥å…·è¿›è¡Œé«˜çº§æ˜¾ç¤ºã€‚</p><h5 id="å…³äºå°†è®­ç»ƒä»£ç å’Œå¯è§†åŒ–åˆ†ç¦»ä»£ç åˆ†ç¦»çš„æŠ€å·§">å…³äºå°†è®­ç»ƒä»£ç å’Œå¯è§†åŒ–åˆ†ç¦»ä»£ç åˆ†ç¦»çš„æŠ€å·§</h5><blockquote><p>Q: In my deep learning codings, I want to visualize tensors in mytraining procedure. Anyway I don't want to mixup the visualizationcoding and training coding which makes my code less maintainable. Inwhat way can I reconstruct my code to better satisfy my task?</p></blockquote><p>A: One way to separate the visualization code from the training codeis to use a callback function. In deep learning, a callback is afunction that is executed at the end of each training epoch. This allowsyou to separate the code for visualizing the training process from thecode that actually trains the model.</p><p>Here is an example of how you might use a callback function tovisualize the training process:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Define a callback function</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">visualize_training</span>(<span class="params">model</span>):</span><br><span class="line">  <span class="comment"># Generate some data to use for visualizing the training process</span></span><br><span class="line">  data = generate_data()</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Use the model to make predictions on the data</span></span><br><span class="line">  predictions = model.predict(data)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Visualize the predictions</span></span><br><span class="line">  visualize(predictions)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Use the callback function as a callback during training</span></span><br><span class="line">model.fit(data, labels, epochs=<span class="number">10</span>, callbacks=[visualize_training])</span><br></pre></td></tr></table></figure><p>This way, the code for visualizing the training process is containedwithin the <code>visualize_training()</code> function, and can be easilyreused or modified without affecting the rest of the training code.</p><p>Here is an example of how you might implement a callback function inPyTorch:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Import the necessary modules</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"></span><br><span class="line"><span class="comment"># Define a callback function</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">visualize_training</span>(<span class="params">model, data_loader</span>):</span><br><span class="line">  <span class="comment"># Loop through the data in the data loader</span></span><br><span class="line">  <span class="keyword">for</span> inputs, labels <span class="keyword">in</span> data_loader:</span><br><span class="line">    <span class="comment"># Use the model to make predictions on the inputs</span></span><br><span class="line">    predictions = model(inputs)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Visualize the predictions</span></span><br><span class="line">    visualize(predictions, labels)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Define a data loader</span></span><br><span class="line">data_loader = DataLoader(dataset, batch_size=<span class="number">32</span>, shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Use the callback function as a callback during training</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">  <span class="keyword">for</span> inputs, labels <span class="keyword">in</span> data_loader:</span><br><span class="line">    <span class="comment"># Perform a training step</span></span><br><span class="line">    output = model(inputs)</span><br><span class="line">    loss = criterion(output, labels)</span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Use the callback after each epoch</span></span><br><span class="line">  visualize_training(model, data_loader)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>æ³¨ï¼šå®é™…ä¸Šè¿™é‡Œçš„Callbackå°±æ˜¯åœ¨æ¯ä¸€è½®è®­ç»ƒçš„ç»“æŸé˜¶æ®µè°ƒç”¨ä¸€ä¸ªå¤–éƒ¨å‡½æ•°å°†éœ€è¦å¯è§†åŒ–çš„æ•°æ®å‘é‡Œè¾¹ä¼ ã€‚æœºå™¨äººç»™çš„ä»£ç å¯ä»¥çœ‹åˆ°ï¼Œä¼ å…¥çš„æ•°æ®æ˜¯ä¸€ä¸ªdataloaderï¼Œä¹Ÿå°±æ„å‘³ç€æ‰€æœ‰çš„æ•°æ®éƒ½è¦é€šè¿‡dataloaderé‡æ–°åŠ è½½ä¸€éã€‚å®ƒçš„å¥½å¤„åœ¨äºå¯ä»¥åœ¨å¤–éƒ¨å‡½æ•°æ ¹æ®éœ€è¦å®šåˆ¶æ•°æ®çš„è¾“å‡ºï¼Œè€Œä¸å¿…åœ¨è®­ç»ƒå‡½æ•°å†…éƒ¨åå¤è°ƒè¯•ä»£ç ã€‚</p><p><a href="https://www.youtube.com/watch?v=UozNlBZ1PFE">NUS workshop:Multiple Instance Learning</a>ï¼Œæ–°åŠ å¡å›½ç«‹å¤§å­¦å…³äºå¤šç¤ºä¾‹å­¦ä¹ çš„è®²åº§ã€‚</p><p>Hometaken notes:</p><ol type="1"><li>Instances can be associated with other information.</li></ol><p>Assign each bag a correct label.</p><p>Visualization</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;ä»¥ä¸‹æ˜¯å®éªŒè¿‡ç¨‹ä¸­å‘ç°é—®é¢˜å¹¶ä¸æœºå™¨äºº&lt;a href=&quot;https://chat.openai.com/chat&quot;&gt;ChatBot&lt;/a&gt;è®¨è®ºçš„è¿‡ç¨‹ã€‚è®°å½•å¦‚ä¸‹ä»¥ä¾¿æ€è·¯çš„å¼€æ‹“ï¼š&lt;/p&gt;
&lt;h4 id=&quot;å…³äºé¢„æµ‹ä¿¡å·å¼‚å¸¸ä¸º0å’Œ1çš„é—®é¢˜&quot;&gt;å…³äºé¢„æµ‹ä¿¡å·å¼‚å¸¸ä¸º0å’Œ1çš„é—®é¢˜&lt;/h4&gt;
&lt;</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>VAD Research Review</title>
    <link href="http://hankislolo.com/2022/12/08/VAD-Research-Review/"/>
    <id>http://hankislolo.com/2022/12/08/VAD-Research-Review/</id>
    <published>2022-12-08T09:36:46.000Z</published>
    <updated>2022-12-09T02:54:05.369Z</updated>
    
    <content type="html"><![CDATA[<p>æœ¬æ–‡æ¡£è®°å½•VADçš„å„ç±»è§£å†³æ–¹æ¡ˆï¼Œå¹¶å¯¹å…¶æ–¹æ³•è¿›è¡Œå½’çº³ã€‚</p><table style="width:100%;"><colgroup><col style="width: 16%"><col style="width: 10%"><col style="width: 16%"><col style="width: 15%"><col style="width: 4%"><col style="width: 16%"><col style="width: 4%"><col style="width: 16%"></colgroup><thead><tr class="header"><th>Title</th><th style="text-align: center;">Keyword</th><th>Idea</th><th style="text-align: center;">Pooling</th><th style="text-align: left;">Advantages</th><th>Drawbacks</th><th>Note</th><th>Comment</th></tr></thead><tbody><tr class="odd"><td><a href="https://link.springer.com/article/10.1007/s11227-021-04190-9">Attentionâ€basedframework for weakly supervised video anomaly detection</a></td><td style="text-align: center;">GAAM, DAAM</td><td><strong>åŒä»»åŠ¡</strong>ç»“åˆï¼ˆå¼‚å¸¸æ³¨æ„åŠ›+è§†é¢‘ç‰¹å¾é‡æ„ï¼‰</td><td style="text-align: center;"></td><td style="text-align: left;"></td><td></td><td>æ–‡ç« æœªå¼€æºï¼Œæ— ä»£ç </td><td></td></tr><tr class="even"><td><a href="https://www.aaai.org/AAAI22Papers/AAAI-6637.LiS.pdf">Self-TrainingMulti-Sequence Learning with Transformer for Weakly Supervised VideoAnomaly Detection</a></td><td style="text-align: center;">MSL</td><td>å°†Instanceæ”¹ä¸ºSequenceï¼Œåœ¨è¿­ä»£ä¼˜åŒ–çš„è¿‡ç¨‹ä¸­é€æ¸å‡å°Sequenceçš„å¤§å°ï¼Œä½¿é¢„æµ‹ä¿¡å·åœ¨æ—¶é—´åŸŸä¸Šé€æ¸åˆ†ç¦»ã€‚ä½¿ç”¨CTEæ¨¡å—ï¼Œå¼•å…¥çš„Convå¯ä»¥ä¿ç•™å±€éƒ¨ä¸Šä¸‹æ–‡ç‰¹å¾</td><td style="text-align: center;"><strong>Sequence-Pooling(Dynamic)</strong></td><td style="text-align: left;">è‡ªé€‚åº”çš„æ¸å˜ä¼˜åŒ–</td><td>å°šæœªå¤ç°ã€‚åˆæ­¥å®éªŒå‘ç°CTEåœ¨å…¨å±€çš„è®­ç»ƒè¿‡ç¨‹ä¸­ä¼šè®©æ‰€æœ‰çš„ç‰¹å¾åˆ†æ•°ä¸‹é™ä¸º0æˆ–è€…1ï¼ˆè¿™ç§ç°è±¡ä¼¼ä¹æ˜¯æ­£å¸¸çš„ï¼Ÿï¼‰è¿‡ç¨‹å®ç°å¾ˆç¹ç</td><td>æ— ä»£ç </td><td></td></tr><tr class="odd"><td><a href="https://ieeexplore.ieee.org/abstract/document/9774889">WeaklySupervised Video Anomaly Detection via Transformer-Enabled TemporalRelation Learning</a></td><td style="text-align: center;">Transformer, Temporal RelationLearning</td><td>åœ¨I3Dç‰¹å¾åå¼•å…¥ä¸Šä¸‹æ–‡çš„Transformerè‡ªæ³¨æ„åŠ›æ¨¡å—ï¼Œå°†ä¸Š<strong>ä¸‹æ–‡ä¿¡æ¯èåˆ</strong>åˆ°æ¯ä¸€ä¸ªç¤ºä¾‹çš„ç‰¹å¾ï¼ˆé«˜é˜¶ï¼‰å½“ä¸­</td><td style="text-align: center;">mean</td><td style="text-align: left;"></td><td></td><td>æœªå¼€æº</td><td>ä¸Šä¸‹æ–‡æ³¨æ„åŠ›è‚¯å®šæ˜¯åˆç†çš„ï¼Œä½†æ˜¯å®ƒæ¯”Convæ¨¡å—æå–å±€éƒ¨ä¿¡æ¯å¿«äº†å¤šå°‘ï¼Ÿ</td></tr><tr class="even"><td><a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136640328.pdf">Self-TrainingMulti-Sequence Learning with Transformer for Weakly Supervised VideoAnomaly Detection</a></td><td style="text-align: center;">PSR (Patch Spatio Relation)</td><td></td><td style="text-align: center;">ä½¿ç”¨äº†RTFMçš„æ± åŒ–æ–¹æ³•ï¼Œé€‰æ‹©äº†top-kmagnitude ï¼ˆç‰¹å¾äºŒèŒƒæ•°ï¼‰</td><td style="text-align: left;"></td><td></td><td></td><td></td></tr><tr class="odd"><td></td><td style="text-align: center;"></td><td></td><td style="text-align: center;"></td><td style="text-align: left;"></td><td></td><td></td><td></td></tr></tbody></table>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;æœ¬æ–‡æ¡£è®°å½•VADçš„å„ç±»è§£å†³æ–¹æ¡ˆï¼Œå¹¶å¯¹å…¶æ–¹æ³•è¿›è¡Œå½’çº³ã€‚&lt;/p&gt;
&lt;table style=&quot;width:100%;&quot;&gt;
&lt;colgroup&gt;
&lt;col style=&quot;width: 16%&quot;&gt;
&lt;col style=&quot;width: 10%&quot;&gt;
&lt;col style=&quot;width</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>VAD Research Logs</title>
    <link href="http://hankislolo.com/2022/12/07/VAD-Research-Logs/"/>
    <id>http://hankislolo.com/2022/12/07/VAD-Research-Logs/</id>
    <published>2022-12-07T09:33:16.000Z</published>
    <updated>2022-12-21T10:33:01.813Z</updated>
    
    <content type="html"><![CDATA[<h3 id="å…³äºè§†é¢‘å¼‚å¸¸æ£€æµ‹çš„æ ¸å¿ƒé—®é¢˜">å…³äºè§†é¢‘å¼‚å¸¸æ£€æµ‹çš„æ ¸å¿ƒé—®é¢˜</h3><hr><p>åœ¨è¿‡å»çš„å®éªŒç ”ç©¶å½“ä¸­å‘ç°è§†é¢‘å¼‚å¸¸æ£€æµ‹çš„å…·ä½“å®ç°æœ‰å¾ˆå¤šç°å®éš¾ä»¥è§£å†³çš„é—®é¢˜ã€‚ä½†æ˜¯å¾ˆå¤šæ–‡ç« å£°ç§°çš„å…·ä½“æ–¹æ³•å´ç¼ºä¹ä»£ç å®ç°ã€‚æœ¬æ–‡å¯¹è¿‡å»çš„æ–‡çŒ®åŠ ä»¥ä»‹ç»å¹¶æ€»ç»“ï¼Œå¹¶æ·»åŠ ä¸€äº›å®éªŒä¸­å‘ç°çš„é—®é¢˜ï¼Œä»¥å¯å‘åç»­çš„å·¥ä½œç»§ç»­æ·±å…¥ã€‚</p><h4 id="mil-multiple-instance-learning-çš„ä¸€èˆ¬æ–¹æ³•">MIL (MultipleInstance Learning) çš„ä¸€èˆ¬æ–¹æ³•</h4><hr><blockquote><p>ä»¥ä¸‹ä¸ºçŸ¥ä¹é«˜èµå›ç­”</p></blockquote><p>å¯¹äºä¸€ä¸ªå…¸å‹çš„MILé—®é¢˜ï¼Œè§£å†³è¿™ä¸ªæ–¹æ³•é€šå¸¸ä¸º<strong>è¿­ä»£ä¼˜åŒ–ï¼ˆalternativeoptimization)ã€‚</strong>ä¹Ÿå°±æ˜¯è¯´ï¼Œæˆ‘ä»¬å…ˆå‡è®¾å·²ç»çŸ¥é“äº†æ‰€æœ‰æ ·æœ¬çš„æ ‡è®°ï¼Œé‚£ä¹ˆå°±å¯ä»¥é€šè¿‡æŸç§ç›‘ç£å­¦ä¹ çš„æ–¹æ³•å¾—åˆ°ä¸€ä¸ªåˆ†ç±»æ¨¡å‹ï¼Œé€šè¿‡è¿™ä¸ªæ¨¡å‹æˆ‘ä»¬å¯ä»¥å¯¹æ¯ä¸ªè®­ç»ƒæ ·æœ¬è¿›è¡Œé¢„æµ‹ï¼Œç„¶åæ›´æ–°å®ƒä»¬çš„æ ‡è®°ï¼Œæˆ‘ä»¬åˆå¯ä»¥æ‹¿è¿™ä¸€æ¬¡æ–°å¾—åˆ°çš„æ ‡è®°é‡æ–°è®­ç»ƒåˆ†ç±»æ¨¡å‹äº†ã€‚æ‰€ä»¥æ•´ä¸ªä¼˜åŒ–è¿‡ç¨‹åˆ†ä¸ºä¸¤éƒ¨åˆ†ï¼šç›‘ç£å­¦ä¹ ï¼Œæ ‡è®°æ›´æ–°<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œåœ¨è®­ç»ƒçš„è¿‡ç¨‹ä¸­ï¼š</p><ol type="1"><li>ç¬¬ä¸€ç‚¹ï¼Œè®­ç»ƒç›‘ç£å­¦ä¹ çš„æ¨¡å‹çš„æ—¶å€™ï¼Œåªä»æ­£æ ·æœ¬åŒ…é‡ŒæŒ‘é€‰è¢«é¢„æµ‹çš„â€œæœ€åƒæ­£ç¡®â€(ä¹Ÿå°±æ˜¯åˆ†ç±»å¾—åˆ†æœ€é«˜)çš„é‚£ä¸€ä¸ªï¼Œæ­£æ ·æœ¬åŒ…é‡Œé¢<strong>å…¶ä»–çš„</strong>æ ·æœ¬ï¼Œä¸ç®¡é¢„æµ‹å‡ºæ¥æ˜¯æ­£çš„è¿˜æ˜¯è´Ÿçš„<strong>éƒ½ä¸è¦äº†</strong>ã€‚è¿™æ˜¯å› ä¸ºï¼Œå…¶å®å¤šç¤ºä¾‹çš„é—®é¢˜ä¹Ÿå¯ä»¥æè¿°ä¸ºï¼Œæ­£æ ·æœ¬åŒ…é‡Œé¢â€œæœ€æ­£ç¡®â€çš„ä¸€ä¸ªæ ·æœ¬æ ‡è®°æ˜¯æ­£çš„ï¼Œè·Ÿå…¶ä»–æ ·æœ¬æ— å…³ã€‚æ‰€ä»¥ï¼Œè¿™ç§é€‰æ‹©ç­–ç•¥æ°æ°æ˜¯ç¬¦åˆé—®é¢˜å®šä¹‰çš„ã€‚<strong>ï¼ˆé€‰æœ€å®¹æ˜“åˆ†ç±»çš„ï¼Œå› ä¸ºå¯èƒ½åªæœ‰ä¸€ä¸ªï¼‰</strong></li><li>ç¬¬äºŒç‚¹ï¼Œå¦‚æœè´Ÿæ ·æœ¬è¶³å¤Ÿå¤šçš„è¯ï¼Œå¯ä»¥åªæŒ‘é€‰æ¯ä¸ªè´Ÿæ ·æœ¬åŒ…é‡Œé¢è¢«é¢„æµ‹â€œæœ€åƒæ­£ç¡®"çš„ä¸€ä¸ªæ ·æœ¬ä½œä¸ºè´Ÿæ ·æœ¬è¿›è¡Œè®­ç»ƒï¼Œè¿™æ ·å­çš„è´Ÿæ ·æœ¬ä¹Ÿå«åšhardsampleæˆ–è€…most violatedsampleã€‚å®è·µä¸Šæ¥è¯´ï¼Œå®ƒä»¬å¯¹äºæ¨¡å‹å¿«é€Ÿæ”¶æ•›æ˜¯æœ€æœ‰æ•ˆçš„ã€‚<strong>ï¼ˆé€‰æœ€éš¾åˆ†ç±»çš„ï¼Œå› ä¸ºæ‰€æœ‰æ ·æœ¬éƒ½æ˜¯è´Ÿçš„ï¼Œå¹¶ä¸”è¦ä½¿æ¨¡å‹èƒ½å¤Ÿæœ‰åŒºåˆ†åº¦ï¼Œè¿™ç§è§‚ç‚¹å¯ä»¥å‚è€ƒæ”¯æŒå‘é‡æœºä¸­çš„æ”¯æŒå‘é‡çš„è§‚ç‚¹ï¼‰</strong><a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a></li></ol><p>å› æ­¤ï¼Œå¯¹äºä¸€ä¸ªç»å…¸çš„MILé—®é¢˜ï¼Œé€šå¸¸çš„ç®—æ³•å®ç°è¿‡ç¨‹åˆ†ä¸ºå¦‚ä¸‹æ­¥éª¤ï¼š</p><p>å¤šç¤ºä¾‹å­¦ä¹ ï¼š</p><p>è¾“å…¥ï¼šæ­£åŒ…ï¼Œè´ŸåŒ…</p><p>è¾“å‡ºï¼š åˆ†ç±»å‡½æ•° <span class="math inline">\(f\)</span></p><p>å°†æ¯ä¸ªæ ‡è®°åŒ…ä¸­çš„æ ·æœ¬åˆå§‹åŒ–ä¸º<strong>åŒ…çš„æ ‡è®°</strong>ï¼Œåˆå§‹åŒ–é›†åˆ<span class="math inline">\(U\)</span> ä¸ºç©ºï¼Œå°†æ‰€æœ‰æ ·æœ¬ (instance)åŠ å…¥æ ·æœ¬é›† <span class="math inline">\(U\)</span></p><p>é‡å¤ä¸‹é¢çš„è¿‡ç¨‹ï¼š</p><ol type="1"><li>å– <strong><span class="math inline">\(U\)</span>ä¸­æ‰€æœ‰æ ·æœ¬</strong> <span class="math inline">\(s_i\)</span> ä»¥åŠæ ‡è®°<span class="math inline">\(y\)</span> <em>è®­ç»ƒ</em> å¾—åˆ°ä¸€ä¸ªåˆ†ç±»å‡½æ•°<span class="math inline">\(f\)</span>ï¼ˆåˆå§‹çŠ¶æ€ï¼šæ‰€æœ‰åŒ…çš„æ ·æœ¬éƒ½å·²ç»åŠ å…¥<span class="math inline">\(U\)</span>ï¼‰</li><li>åˆ©ç”¨ <span class="math inline">\(f\)</span> <em>é¢„æµ‹</em><strong>è®­ç»ƒé›†çš„æ‰€æœ‰æ ·æœ¬</strong>çš„æ ‡è®° <span class="math inline">\(\hat{y}\)</span></li><li>æ¸…ç©º <span class="math inline">\(U\)</span></li><li>å¯¹äºæ¯ä¸ªæ­£æ ‡è®°åŒ…ï¼Œé€‰å– <span class="math inline">\(f\)</span>é¢„æµ‹å¾—åˆ†æœ€é«˜çš„æ ·æœ¬ <span class="math inline">\(s_{p\_max}\)</span>åŠ å…¥é›†åˆ <span class="math inline">\(U\)</span>ï¼ˆé€‰æœ€å®¹æ˜“åˆ†ç±»çš„ä¸€ä¸ªï¼‰</li><li>å¯¹äºæ¯ä¸ªè´Ÿæ ‡è®°åŒ…ï¼Œé€‰å– <span class="math inline">\(f\)</span>é¢„æµ‹å¾—åˆ†æœ€é«˜çš„æ ·æœ¬ <span class="math inline">\(s_{n\_max}\)</span>åŠ å…¥é›†åˆ <span class="math inline">\(U\)</span>ï¼ˆé€‰æœ€éš¾åˆ†ç±»çš„ä¸€ä¸ªæˆ–å¤šä¸ªï¼‰</li></ol><p>ç›´åˆ° <span class="math inline">\(U\)</span> ä¸­ä¸åŒ…å«æ­£æ ·æœ¬ä¸ºæ­¢.</p><p>è¿”å› <span class="math inline">\(f\)</span>.</p><p>ä¼ªä»£ç ï¼šï¼ˆæŒ‰ç…§ä»¥ä¸Šç®—æ³•çš„ç†è§£å†™çš„ä¼ªä»£ç ï¼‰</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Input: Negative_bags (N), Positive_bags (P)</span></span><br><span class="line"><span class="string">Output: Classifier f</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Args:</span></span><br><span class="line"><span class="string">iter_num: iterations of each training stage</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="comment"># Initialize labels for each of the instances of neg/pos bags</span></span><br><span class="line"><span class="keyword">for</span> instance, label <span class="keyword">in</span> N_bags:</span><br><span class="line">label = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> instance, label <span class="keyword">in</span> P_bags:</span><br><span class="line">label = <span class="number">1</span></span><br><span class="line">U.add(N, P)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Iterative Optimization</span></span><br><span class="line"><span class="keyword">while</span> <span class="keyword">not</span> condition:</span><br><span class="line">  <span class="comment"># Train model with current pseudo-labelled U</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(iter_num):</span><br><span class="line">        model.train(U)  <span class="comment"># All positive instances are assigned as 1, else 0</span></span><br><span class="line">    U.clear()</span><br><span class="line">    N_bag, P_bag = [], []</span><br><span class="line">    <span class="keyword">for</span> bag <span class="keyword">in</span> N:</span><br><span class="line">        neg_instances = model.inference(bag)</span><br><span class="line">        N_bag.append(<span class="built_in">max</span>(neg_instances))  <span class="comment"># Pooling stage, add the most likely instance (representative) into training set U.</span></span><br><span class="line">    <span class="keyword">for</span> bag <span class="keyword">in</span> P:</span><br><span class="line">        pos_instances = model.inference(bag)</span><br><span class="line">        P_bag.append(<span class="built_in">max</span>(pos_instances))  <span class="comment"># Max-pooling</span></span><br><span class="line">    U.add(N_bag, P_bag)</span><br></pre></td></tr></table></figure><p>åœ¨è¿­ä»£å¾ªç¯çš„è¿‡ç¨‹ä¸­ï¼Œ1~3ä¸ºè¿­ä»£æ¨ç†é˜¶æ®µï¼Œ4~5ä¸ºæ± åŒ–é˜¶æ®µ(Aggregation/Pooling) ã€‚</p><p>æ± åŒ–æ“ä½œä¼šä¸¢å¤±å¤§é‡çš„ä¸å¿…è¦æ•°æ®ã€‚<del>ä»¥ä»¥ä¸Šæ–¹æ³•ä¸ºä¾‹ï¼Œæ± åŒ–é‡‡ç”¨top-1åˆ™æ¯ä¸€è½®è¿­ä»£çš„æ ·æœ¬ä¸ªæ•°éšåŒ…çš„å¤§å°æŒ‡æ•°çº§ä¸‹é™ã€‚åœ¨æ± åŒ–å¼€å§‹å‰ï¼Œè®¾æ¯ä¸ªåŒ…å«æœ‰çš„æ ·æœ¬æ•°é‡å¤§å°<span class="math inline">\(N\)</span> ç›¸åŒï¼Œ<span class="math inline">\(U\)</span> ä¸­çš„åŒ…ä¸ªæ•°ä¸º <span class="math inline">\(m\)</span> ï¼Œåˆ™å½“å‰å‚ä¸æ¨¡å‹è®­ç»ƒçš„æ ·æœ¬ <span class="math inline">\(I\)</span> çš„ä¸ªæ•°ä¸º <span class="math inline">\(N\times m\)</span>. åœ¨æ­£è´ŸåŒ…å¹³è¡¡çš„çŠ¶æ€ä¸‹ï¼Œæ± åŒ–æ“ä½œä½¿å¾— <span class="math inline">\(U\)</span> åŒ…å«çš„æ ·æœ¬ä¸ªæ•°ä¸‹é™ä¸º <span class="math inline">\(m\)</span>. å¦‚æœä¸èƒ½ä¿è¯ <span class="math inline">\(m &gt;&gt; N\)</span>ï¼Œ</del></p><p>é™¤äº†åˆå§‹åŒ–å°†æ‰€æœ‰æ ·æœ¬å…¨éƒ¨åŠ å…¥<span class="math inline">\(U\)</span>çš„æƒ…å†µï¼Œæ¯ä¸€æ¬¡è¿­ä»£è®­ç»ƒçš„æ­£è´Ÿæ ·æœ¬æ•°ä¸æ± åŒ–æ“ä½œå¾—åˆ°çš„æ ·æœ¬æ€»é‡ç›¸åŒï¼ˆåœ¨æœ¬ä¾‹é‡Œï¼Œé‡‡ç”¨æœ€å¤§æ± åŒ–æ¯ä¸ªåŒ…æŒ‘é€‰å‡ºä¸€ä¸ªæ ·æœ¬ä½œä¸ºä»£è¡¨ï¼‰ã€‚æ¯ä¸€æ¬¡è¿­ä»£å®Œçš„æ¨¡å‹åœ¨æ¨ç†è¿‡ç¨‹ä¸­ä¼šå¯¹æ­£è´ŸåŒ…é‡Œé¢çš„æ‰€æœ‰æ ·æœ¬é‡æ–°æ‰“ä¸Š0/1æ ‡ç­¾ã€‚</p><hr><blockquote><p>å¯¹äºä¸€èˆ¬çš„MILä¾‹å­ï¼Œæ›´å…¸å‹çš„åº”ç”¨ä¾‹å­æ˜¯ä»¥åŒ…ä½œä¸ºé¢„æµ‹å•å…ƒè¿›è¡Œä»»åŠ¡ï¼Œè€Œä¸æ˜¯è€ƒè™‘åŒ…é‡Œçš„å®ä¾‹ã€‚ä½†æ˜¯é€šè¿‡åŠ å…¥å…ˆéªŒï¼ˆæ³¨æ„åŠ›ã€å¯¹æ¯”å­¦ä¹ ï¼‰çŸ¥è¯†ï¼Œæœ‰å¯èƒ½è®©å®ä¾‹çº§çš„é¢„æµ‹æˆä¸ºå¯èƒ½ã€‚</p></blockquote><p>ChatGPTç»™çš„MILä¼ªä»£ç ï¼š</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">function MIL(instance_groups, labels):</span><br><span class="line"></span><br><span class="line">  for each group, label in zip(instance_groups, labels):</span><br><span class="line">    for instance in group:</span><br><span class="line">      predict_label = classify(instance)</span><br><span class="line">      if predict_label == label:</span><br><span class="line">        # instance is correctly classified</span><br><span class="line">        update_weights(instance, predict_label)</span><br><span class="line">      else:</span><br><span class="line">        # instance is misclassified</span><br><span class="line">        update_weights(instance, label)</span><br><span class="line"></span><br><span class="line">  return classifier</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>è¯¥ä¼ªä»£ç å®ç°äº†MILç®—æ³•çš„åŸºæœ¬æ€è·¯ã€‚å®ƒé¦–å…ˆéå†æ‰€æœ‰çš„å®ä¾‹ç»„å’Œæ ‡ç­¾ï¼Œå¹¶å¯¹æ¯ä¸ªå®ä¾‹è¿›è¡Œåˆ†ç±»ã€‚å¦‚æœé¢„æµ‹çš„æ ‡ç­¾ä¸çœŸå®æ ‡ç­¾ç›¸åŒï¼Œåˆ™æ›´æ–°åˆ†ç±»å™¨çš„æƒé‡ï¼Œå¦åˆ™æ›´æ–°å®ä¾‹çš„æƒé‡ã€‚æœ€åï¼Œå®ƒè¿”å›è®­ç»ƒåçš„åˆ†ç±»å™¨ã€‚</p><p>ä»MILçš„ä¸€èˆ¬æ±‚è§£èŒƒå¼æ¥çœ‹ï¼ŒMILå…·æœ‰ä»¥ä¸‹ç‰¹ç‚¹ï¼š</p><ul><li>ç¤ºä¾‹ï¼ˆinstance,ä»¥ä¸Šç§°ä¸ºæ ·æœ¬ï¼Œä¸ºæ–¹ä¾¿è®¨è®ºä»¥ä¸‹å°†å…¶ç§°ä¸ºâ€œç¤ºä¾‹â€ï¼‰å…·æœ‰Permutation-Invarianceç‰¹æ€§ï¼Œå³äº¤æ¢ç¤ºä¾‹çš„ä½ç½®ä¸ä¼šå¯¹æ‰“åˆ†é€ æˆå½±å“ï¼ˆæ‰“åˆ†ä¸ä½ç½®æ— å…³ï¼‰</li><li>è®­ç»ƒçš„åŸºæœ¬å•å…ƒæ˜¯Bagï¼Œä¸æ˜¯å•ä¸ªçš„Instancesã€‚åœ¨é¢„æµ‹è¿‡ç¨‹ä¸­ï¼Œä¹Ÿæ˜¯é€Bagè¿›è¡Œé¢„æµ‹ã€‚</li><li>æ•°æ®çš„å¯è§†åŒ–ã€èšåˆæ–¹æ³•ã€æŸå¤±å‡½æ•°æ„æˆMILçš„åŸºæœ¬è¦ç´ ã€‚å…¶ä¸­ï¼Œæ•°æ®å¯è§†åŒ–ç”¨äºå¯¹æ•°æ®åˆ†å¸ƒè¿›è¡Œå…ˆéªŒçš„åˆ¤æ–­ï¼Œè®¾è®¡èšåˆæ–¹æ³•æ ¹æ®æ•°æ®åˆ†å¸ƒé€‰æ‹©å‡ºæœ€å…·æœ‰ä»£è¡¨æ€§çš„ç‰¹å®šæ‰‹æ®µæ¥æè¿°Bagçš„ç‰¹å¾ã€‚æŸå¤±å‡½æ•°åˆ™åŸºäºèšåˆå€¼ï¼Œäººä¸ºé€‰å®šä¸€ä¸ªæœ‰åˆ©äºæ¨¡å‹æ‹Ÿåˆæ¥è¿›è¡Œæ¨¡å‹çš„å­¦ä¹ ã€‚</li></ul><p>æ³¨æ„è¿™é‡Œçš„MILå’Œç¬¬ä¸€éƒ¨åˆ†MILçš„åŒºåˆ«ã€‚è¿™é‡Œçš„MILçš„å¤„ç†çº§åˆ«ä»è®­ç»ƒåˆ°é¢„æµ‹ä»»åŠ¡éƒ½æ˜¯åŒ…çº§åˆ«çš„ï¼ˆBag-Levelï¼‰ï¼Œå› æ­¤å®ƒå¹¶ä¸ä¼šå»å…³æ³¨æ¯ä¸€ä¸ªå®ä¾‹çš„å…·ä½“ä¿¡æ¯ã€‚åœ¨å®é™…çš„ä»»åŠ¡è¦æ±‚ä¸­ï¼Œå¾€å¾€éœ€è¦è·å¾—å®ä¾‹çº§åˆ«çš„æ ‡ç­¾ã€‚è¿™æ—¶å€™ï¼Œå°±ä¸å¾—ä¸æŠŠåŒ…å†…éƒ¨çš„å…³ç³»æŠ½å–å‡ºæ¥å¤„ç†äº†ã€‚å¦‚ç¬¬ä¸€éƒ¨åˆ†çš„MILï¼Œå…¶é‡‡ç”¨æœ€å¤§å€¼èšåˆå‡½æ•°é€‰æ‹©å…·æœ‰ä»£è¡¨æ€§çš„å®ä¾‹åï¼Œç”¨SVMçš„æ€è·¯æ‰¾åˆ°å®ä¾‹é—´çš„è¶…å¹³é¢ã€‚ä½†æ˜¯ä¸€æ—¦åœ¨åˆå§‹é˜¶æ®µé€‰æ‹©åˆ°å±äºæ­£åŒ…çš„è´Ÿæ ·æœ¬ï¼Œè¯¯å·®å°±ä¼šé€æ¸ç´¯ç§¯è¿›è€Œæ¨¡å‹å¤±æ•ˆã€‚</p><hr><h4 id="æŸå¤±å‡½æ•°çš„é€‰æ‹©">æŸå¤±å‡½æ•°çš„é€‰æ‹©</h4><h5 id="hinge-loss-åˆé¡µæŸå¤±å‡½æ•°">Hinge Loss ï¼ˆåˆé¡µæŸå¤±å‡½æ•°ï¼‰</h5><p>å‡è®¾ä½ ä½¿ç”¨çš„æ˜¯MLPä½œä¸ºMILæ¨¡å‹ï¼Œæ¯ä¸€è½®è®­ç»ƒè¾“å…¥çš„æ˜¯ä¸€å¯¹æ­£è´Ÿå®ä¾‹ç»„ï¼Œå¹¶ä½¿ç”¨æœ€å¤§å€¼å‡½æ•°ä½œä¸ºèšåˆå‡½æ•°ï¼Œç„¶åç”¨sigmoidå‡½æ•°å°†èšåˆç»“æœæ˜ å°„åˆ°[0,1]ä¹‹é—´ã€‚é‚£ä¹ˆï¼Œä½ å¯ä»¥ä½¿ç”¨HingeLossä½œä¸ºç›®æ ‡æŸå¤±å‡½æ•°æ¥è¿›è¡Œåå‘ä¼ æ’­ï¼Œè¾“å…¥ç›®æ ‡æŸå¤±å‡½æ•°çš„å€¼å°±æ˜¯sigmoidå‡½æ•°çš„è¾“å‡ºã€‚</p><p>å…·ä½“æ¥è¯´ï¼Œå‡è®¾ä½ æœ‰ä¸€ä¸ªæ­£æ ·æœ¬<span class="math inline">\(x_1\)</span>å’Œä¸€ä¸ªè´Ÿæ ·æœ¬<span class="math inline">\(x_2\)</span>ï¼Œå¹¶å°†å®ƒä»¬åˆå¹¶ä¸ºä¸€ä¸ªè¾“å…¥<span class="math inline">\(x\)</span>ï¼Œé‚£ä¹ˆä½ å¯ä»¥ä½¿ç”¨MLPæ¥è®¡ç®—å®ƒä»¬çš„èšåˆå€¼<span class="math inline">\(y\)</span>ï¼Œå…·ä½“æ¥è¯´ï¼š</p><p><span class="math inline">\(y = \max({f_{MLP}(x_1),f_{MLP}(x_2)})\)</span></p><p>å…¶ä¸­<span class="math inline">\(f_{MLP}\)</span>è¡¨ç¤ºMLPæ¨¡å‹çš„è¾“å‡ºã€‚ç„¶åï¼Œä½ å¯ä»¥ä½¿ç”¨sigmoidå‡½æ•°æ¥æ˜ å°„<span class="math inline">\(y\)</span>åˆ°[0,1]ä¹‹é—´ï¼Œå³ï¼š</p><p><span class="math inline">\(z = \sigma(y)\)</span></p><p>å…¶ä¸­<span class="math inline">\(\sigma\)</span>è¡¨ç¤ºsigmoidå‡½æ•°ã€‚æœ€åï¼Œä½ å¯ä»¥ä½¿ç”¨HingeLossæ¥è®¡ç®—æ¨¡å‹çš„æŸå¤±å€¼ï¼Œå…·ä½“æ¥è¯´ï¼š</p><p><span class="math inline">\(L = \max({0, 1 - z})\)</span></p><p>è¿™é‡Œçš„<span class="math inline">\(L\)</span>è¡¨ç¤ºæ¨¡å‹çš„æŸå¤±å€¼ï¼Œ<span class="math inline">\(1\)</span>è¡¨ç¤ºæ­£æ ·æœ¬çš„æ ‡ç­¾ï¼Œ<span class="math inline">\(z\)</span>è¡¨ç¤ºsigmoidå‡½æ•°çš„è¾“å‡ºã€‚</p><p>éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œåœ¨ä½¿ç”¨HingeLossä½œä¸ºç›®æ ‡æŸå¤±å‡½æ•°æ—¶ï¼Œè¿˜éœ€è¦è€ƒè™‘å…¶å®ƒå› ç´ ï¼Œæ¯”å¦‚æ ·æœ¬æƒé‡ã€æ­£è´Ÿæ ·æœ¬æ¯”ä¾‹ç­‰ã€‚</p><p>å…·ä½“æ¥è¯´ï¼Œå¯¹äºä¸€ä¸ªæ ·æœ¬<span class="math inline">\(x\)</span>ï¼Œå¦‚æœå®ƒæ˜¯æ­£æ ·æœ¬ï¼Œé‚£ä¹ˆå…¶æƒé‡<span class="math inline">\(w_x\)</span>å¯ä»¥è®¾ä¸º1ï¼›å¦‚æœå®ƒæ˜¯è´Ÿæ ·æœ¬ï¼Œé‚£ä¹ˆå…¶æƒé‡<span class="math inline">\(w_x\)</span>å¯ä»¥è®¾ä¸ºæ­£è´Ÿæ ·æœ¬æ¯”ä¾‹çš„å€’æ•°ï¼Œå³<span class="math inline">\(w_x = \frac{1}{p}\)</span>ï¼Œå…¶ä¸­<span class="math inline">\(p\)</span>è¡¨ç¤ºæ­£è´Ÿæ ·æœ¬æ¯”ä¾‹ã€‚è¿™æ ·å¯ä»¥ç¡®ä¿æ­£è´Ÿæ ·æœ¬åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­è´¡çŒ®çš„æŸå¤±å€¼ç›¸ç­‰ã€‚</p><p>åŒæ—¶ï¼Œéœ€è¦æ³¨æ„çš„æ˜¯ï¼Œä½¿ç”¨HingeLossä½œä¸ºç›®æ ‡æŸå¤±å‡½æ•°æ—¶ï¼Œå¯èƒ½ä¼šå‡ºç°æ¢¯åº¦æ¶ˆå¤±æˆ–çˆ†ç‚¸çš„é—®é¢˜ã€‚å› æ­¤ï¼Œåœ¨ä½¿ç”¨HingeLossæ—¶ï¼Œéœ€è¦æ³¨æ„æ¨¡å‹çš„<strong>å‚æ•°åˆå§‹åŒ–æ–¹å¼</strong>ï¼Œå¹¶é€‰æ‹©åˆé€‚çš„ä¼˜åŒ–ç®—æ³•ï¼Œä»¥é¿å…æ¢¯åº¦æ¶ˆå¤±æˆ–çˆ†ç‚¸çš„é—®é¢˜ã€‚</p><p>é™¤äº†HingeLossä¹‹å¤–ï¼Œè¿˜å¯ä»¥ä½¿ç”¨å…¶å®ƒçš„æŸå¤±å‡½æ•°ä½œä¸ºç›®æ ‡æŸå¤±å‡½æ•°ï¼Œä¾‹å¦‚äº¤å‰ç†µæŸå¤±ï¼ˆCross-EntropyLossï¼‰ã€å¹³æ–¹æŸå¤±ï¼ˆSquare Lossï¼‰ã€æŒ‡æ•°æŸå¤±ï¼ˆExponential Lossï¼‰ç­‰ã€‚</p><p>å…·ä½“æ¥è¯´ï¼Œå¯¹äºä¸€ä¸ªæ ·æœ¬<span class="math inline">\(x\)</span>ï¼Œå¦‚æœå®ƒæ˜¯æ­£æ ·æœ¬ï¼Œé‚£ä¹ˆå…¶æƒé‡<span class="math inline">\(w_x\)</span>å¯ä»¥è®¾ä¸º1ï¼›å¦‚æœå®ƒæ˜¯è´Ÿæ ·æœ¬ï¼Œé‚£ä¹ˆå…¶æƒé‡<span class="math inline">\(w_x\)</span>å¯ä»¥è®¾ä¸ºæ­£è´Ÿæ ·æœ¬æ¯”ä¾‹çš„å€’æ•°ï¼Œå³<span class="math inline">\(w_x = \frac{1}{p}\)</span>ï¼Œå…¶ä¸­<span class="math inline">\(p\)</span>è¡¨ç¤ºæ­£è´Ÿæ ·æœ¬æ¯”ä¾‹ã€‚ç„¶åï¼Œå¯ä»¥ä½¿ç”¨å¦‚ä¸‹æ–¹æ³•æ¥è®¡ç®—æŸå¤±å€¼ï¼š</p><ul><li>äº¤å‰ç†µæŸå¤±ï¼š<span class="math inline">\(L_x = -w_x\log{z_x}\)</span>ï¼Œå…¶ä¸­<span class="math inline">\(z_x\)</span>è¡¨ç¤ºæ¨¡å‹å¯¹æ ·æœ¬<span class="math inline">\(x\)</span>çš„é¢„æµ‹å€¼ã€‚</li><li>å¹³æ–¹æŸå¤±ï¼š<span class="math inline">\(L_x = w_x (1 -z_x)^2\)</span>ï¼Œå…¶ä¸­<span class="math inline">\(z_x\)</span>è¡¨ç¤ºæ¨¡å‹å¯¹æ ·æœ¬<span class="math inline">\(x\)</span>çš„é¢„æµ‹å€¼ã€‚</li><li>æŒ‡æ•°æŸå¤±ï¼š<span class="math inline">\(L_x = w_x \exp{(1 -z_x)}\)</span>ï¼Œå…¶ä¸­<span class="math inline">\(z_x\)</span>è¡¨ç¤ºæ¨¡å‹å¯¹æ ·æœ¬<span class="math inline">\(x\)</span>çš„é¢„æµ‹å€¼ã€‚</li></ul><p>ä¸Šé¢çš„æŸå¤±å‡½æ•°æ˜¯å¸¸ç”¨çš„ç›®æ ‡æŸå¤±å‡½æ•°ï¼Œä½†å¹¶ä¸æ˜¯å”¯ä¸€çš„é€‰æ‹©ã€‚æ ¹æ®å®é™…æƒ…å†µï¼Œå¯ä»¥é€‰æ‹©åˆé€‚çš„ç›®æ ‡æŸå¤±å‡½æ•°ï¼Œä»¥ä¾¿æ›´å¥½åœ°æ‹Ÿåˆæ¨¡å‹ã€‚</p><h5 id="æŒ‡æ•°æŸå¤±å‡½æ•°">æŒ‡æ•°æŸå¤±å‡½æ•°</h5><p>æŒ‡æ•°æŸå¤±å‡½æ•°æ˜¯ä¸€ç§ç”¨äºäºŒåˆ†ç±»é—®é¢˜çš„ç›®æ ‡æŸå¤±å‡½æ•°ï¼Œå®ƒå¯ä»¥ç”¨æ¥è¡¡é‡é¢„æµ‹å€¼ä¸çœŸå®å€¼ä¹‹é—´çš„å·®è·ã€‚æŒ‡æ•°æŸå¤±å‡½æ•°çš„å…¬å¼å¦‚ä¸‹ï¼š<span class="math display">\[L(y, \hat{y}) = \begin{cases} - \log(\hat{y_i}) &amp; \text{if } y_i = 1\\  - \log(1 - \hat{y_i}) &amp; \text{if } y_i = 0 \end{cases}\]</span></p><hr><h4 id="èšåˆå‡½æ•°çš„é€‰æ‹©">èšåˆå‡½æ•°çš„é€‰æ‹©</h4><p>åœ¨è¿›è¡ŒMILæ—¶ï¼Œéœ€è¦é€‰æ‹©ä¸€ä¸ªåˆé€‚çš„èšåˆå‡½æ•°æ¥å¯¹å¤šä¸ªæ•°æ®é›†çš„é¢„æµ‹ç»“æœè¿›è¡Œèšåˆã€‚å¸¸ç”¨çš„èšåˆå‡½æ•°åŒ…æ‹¬<strong>å¹³å‡å€¼ï¼ˆåŠ æƒå¹³å‡å€¼ï¼‰èšåˆå‡½æ•°</strong>å’Œ<strong>æœ€å¤§å€¼èšåˆå‡½æ•°</strong>ç­‰ã€‚</p><h5 id="å¹³å‡å€¼èšåˆå‡½æ•°">å¹³å‡å€¼èšåˆå‡½æ•°</h5><p>å¹³å‡å€¼èšåˆå‡½æ•°æ˜¯ä¸€ç§å¸¸ç”¨çš„èšåˆå‡½æ•°ï¼Œå®ƒå°†å¤šä¸ªæ•°æ®é›†çš„é¢„æµ‹ç»“æœæ±‚å¹³å‡å€¼ã€‚å¹³å‡å€¼èšåˆå‡½æ•°çš„å…¬å¼å¦‚ä¸‹ï¼š</p><p><span class="math inline">\(f(y_1, y_2, \dots, y_n) = \frac{1}{n}\sum_{i=1}^{n} y_i\)</span></p><p>å…¶ä¸­ï¼Œ<span class="math inline">\(y_1, y_2, \dots, y_n\)</span>æ˜¯å¤šä¸ªæ•°æ®é›†çš„é¢„æµ‹ç»“æœï¼Œ<span class="math inline">\(n\)</span>æ˜¯æ•°æ®é›†çš„æ•°é‡ã€‚</p><p>åŠ æƒå¹³å‡å€¼èšåˆå‡½æ•°æ˜¯å¦ä¸€ç§å¸¸ç”¨çš„èšåˆå‡½æ•°ï¼Œå®ƒå°†å¤šä¸ªæ•°æ®é›†çš„é¢„æµ‹ç»“æœæŒ‰ç…§ä¸€å®šçš„æƒé‡è¿›è¡ŒåŠ æƒå¹³å‡ã€‚åŠ æƒå¹³å‡å€¼èšåˆå‡½æ•°çš„å…¬å¼å¦‚ä¸‹ï¼š</p><p><span class="math inline">\(f(y_1, y_2, \dots, y_n) =\frac{\sum_{i=1}^{n} w_i y_i}{\sum_{i=1}^{n} w_i}\)</span></p><p>å…¶ä¸­ï¼Œ<span class="math inline">\(y_1, y_2, \dots, y_n\)</span>æ˜¯å¤šä¸ªæ•°æ®é›†çš„é¢„æµ‹ç»“æœï¼Œ<span class="math inline">\(w_1, w_2, \dots,w_n\)</span> æ˜¯æ•°æ®é›†çš„æƒé‡ï¼Œ<span class="math inline">\(n\)</span>æ˜¯æ•°æ®é›†çš„æ•°é‡ã€‚</p><h5 id="æœ€å¤§å€¼èšåˆå‡½æ•°">æœ€å¤§å€¼èšåˆå‡½æ•°</h5><p>æœ€å¤§å€¼èšåˆå‡½æ•°çš„å…¬å¼å¦‚ä¸‹ï¼š</p><p><span class="math inline">\(f(y_1, y_2, \dots, y_n) = \max(y_1, y_2,\dots, y_n)\)</span></p><p>å…¶ä¸­ï¼Œ<span class="math inline">\(y_1, y_2, \dots, y_n\)</span>æ˜¯å¤šä¸ªæ•°æ®é›†çš„é¢„æµ‹ç»“æœï¼Œ<span class="math inline">\(n\)</span>æ˜¯æ•°æ®é›†çš„æ•°é‡ã€‚</p><hr><h4 id="è¾“å…¥çš„é¢„å¤„ç†">è¾“å…¥çš„é¢„å¤„ç†</h4><p>åœ¨é‡‡ç”¨é«˜æ–¯åˆ†å¸ƒå¯¹å®ä¾‹ç»„è¿›è¡Œé¢„å¤„ç†æ—¶ï¼Œé¢„å¤„ç†é˜¶æ®µåº”å½“å‘ç”Ÿåœ¨å®ä¾‹é€å…¥ MILæ¨¡å‹ä¹‹å‰ã€‚è¿™æ˜¯å› ä¸ºï¼Œé¢„å¤„ç†é˜¶æ®µçš„ç›®çš„æ˜¯å¯¹å®ä¾‹ç»„è¿›è¡Œæ ‡å‡†åŒ–ï¼Œä»¥ä¾¿æ›´å¥½åœ°é€å…¥MIL æ¨¡å‹è¿›è¡Œå¤„ç†ã€‚</p><p>é‡‡ç”¨é«˜æ–¯åˆ†å¸ƒè¿›è¡Œé¢„å¤„ç†çš„æµç¨‹å¯ä»¥ç®€è¿°å¦‚ä¸‹ï¼šé¦–å…ˆï¼Œè®¡ç®—å®ä¾‹ç»„çš„å‡å€¼å’Œæ ‡å‡†å·®ï¼›ç„¶åï¼Œä½¿ç”¨å‡å€¼å’Œæ ‡å‡†å·®å¯¹å®ä¾‹ç»„è¿›è¡Œæ ‡å‡†åŒ–ï¼Œå³å°†å®ä¾‹ç»„çš„æ¯ä¸ªå®ä¾‹å‡å»å‡å€¼ï¼Œå†é™¤ä»¥æ ‡å‡†å·®ï¼›æœ€åï¼Œå°†æ ‡å‡†åŒ–åçš„å®ä¾‹ç»„é€å…¥MIL æ¨¡å‹è¿›è¡Œå¤„ç†ã€‚</p><p>å¦å¤–ï¼Œåœ¨å®ä¾‹ç»„é€å…¥ MIL æ¨¡å‹ä¹‹åï¼Œä½ ä¹Ÿå¯ä»¥ä½¿ç”¨é«˜æ–¯åˆ†å¸ƒå¯¹ MILæ¨¡å‹çš„æ¿€æ´»å€¼è¿›è¡Œé¢„å¤„ç†ã€‚è¿™æ ·åšçš„ç›®çš„æ˜¯è®©æ¿€æ´»å€¼æ›´å¥½åœ°æ‹Ÿåˆé«˜æ–¯åˆ†å¸ƒï¼Œä»è€Œæ›´å¥½åœ°é€‚åº”MIL æ¨¡å‹çš„å¤„ç†é€»è¾‘ã€‚ä½†æ˜¯ï¼Œè¿™ç§æ–¹æ³•çš„ç²¾åº¦å¯èƒ½æ¯”é€å…¥ MILæ¨¡å‹ä¹‹å‰çš„é¢„å¤„ç†æ–¹æ³•ä½ä¸€äº›ï¼Œå› ä¸ºåœ¨ MILæ¨¡å‹çš„å¤„ç†è¿‡ç¨‹ä¸­å¯èƒ½ä¼šä¸¢å¤±ä¸€äº›ä¿¡æ¯ã€‚</p><hr><h4 id="vad-ä¸é‚£ä¹ˆmilçš„mil">VAD: ä¸é‚£ä¹ˆMILçš„MIL</h4><p>VADå¯ä»¥æŠ½è±¡ä¸ºä¸€ä¸ªå…¸å‹çš„å¤šç¤ºä¾‹å­¦ä¹ æ¨¡å‹ã€‚ç”±äºæ„Ÿå…´è¶£çš„æ­£æ ·æœ¬è§†é¢‘ç‰‡æ®µåªå ä¸€ä¸ªè§†é¢‘æ ·æœ¬çš„ä¸€ä¸ªå°éƒ¨åˆ†ï¼Œå› æ­¤å¯ä»¥ç”¨ä¸€ä¸ªå®Œæ•´çš„è§†é¢‘(video) ä½œä¸ºä¸€ä¸ªåŒ… (bag) ï¼Œè§†é¢‘çš„éƒ¨åˆ†ç‰‡æ®µ (clip) ä½œä¸ºç¤ºä¾‹(instance)ï¼Œæ¯ä¸ªåŒ…æ ¹æ®æ˜¯å¦å«æœ‰æ­£ (positive) ç‰‡æ®µç¤ºä¾‹ç»™å®šä¸€ä¸ªç²—ç²’åº¦çš„æ ‡ç­¾(bag label)ã€‚åœ¨æœ€è¿‘çš„ç ”ç©¶å½“ä¸­ï¼Œä½¿ç”¨MILæ–¹æ³•è§£å†³VADé—®é¢˜çš„æ–¹æ³•è¢«å½’ä¸ºWS-VAD(weakly supervised)ã€‚ç›´æ¥ç”¨MILå¯¹VADä»»åŠ¡å»ºæ¨¡å­˜åœ¨ä¸€äº›é‡è¦é—®é¢˜ï¼š</p><ol type="1"><li>æ„å»ºå‡ºçš„åŒ…è´¨é‡ä¼šå½±å“åˆ°é¢„æµ‹å‡½æ•° <span class="math inline">\(f\)</span>çš„è¡¨ç°ã€‚ç”±äºè¿­ä»£è¿‡ç¨‹ä¸­è®­ç»ƒé›†å®é™…ä¸Šæ˜¯æ¯ä¸€è½®ä»æ­£è´ŸåŒ…å½“ä¸­é€‰å‡ºæ¥çš„ä»£è¡¨ï¼ŒåŒ…çš„æ•°é‡å†³å®šäº†æ¯ä¸€è½®è¿­ä»£çš„æ•°æ®é‡å¤§å°ã€‚</li><li>ä¸æ ‡å‡†çš„MILä¸åŒçš„æ˜¯ï¼Œ<strong>VADçš„instancesä¹‹é—´æ˜¯å…·æœ‰æ—¶åºå…³ç³»çš„</strong>ï¼Œè€Œä¸”éšç€é‡‡æ ·ç‰‡æ®µé•¿åº¦çš„å˜åŒ–ï¼Œç¤ºä¾‹çš„ä½ç»´åº¦ç‰¹å¾ä¹Ÿåœ¨å˜ã€‚</li><li>å¯èƒ½ä¼šå¯¹MILæ¨¡å‹é€ æˆè‡´å‘½å½±å“çš„æ˜¯å¯¹è§†é¢‘å¼‚å¸¸çš„å®šä¹‰ï¼šè¢«å®šä¹‰ä¸ºå¼‚å¸¸çš„ç‰‡æ®µé€šå¸¸æ˜¯<strong>è‹¥å¹²ä¸ªè¿ç»­ç¤ºä¾‹</strong>ï¼ˆè§†é¢‘ç‰‡æ®µï¼‰çš„ç»„åˆã€‚<strong>å…¶ä¸­çš„ä»»ä½•ä¸€ä¸ªç¤ºä¾‹</strong>å¯¹ä¸Šè¿°åˆ†ç±»å™¨<span class="math inline">\(f\)</span>è€Œè¨€éƒ½<strong>ä¸ä¼š</strong>è¢«è®­ç»ƒä¸ºæ­£æ ‡è®°ã€‚å¦‚æœå¢åŠ ç¤ºä¾‹é•¿åº¦çš„é‡‡æ ·é•¿åº¦ï¼Œä¸€æ–¹é¢ä¼šä½¿æ•°æ®é›†çš„ç¤ºä¾‹é‡æ€»ä½“å‡å°‘ï¼ŒæŸå¤±ç»†èŠ‚ä¿¡æ¯ï¼›å¦ä¸€æ–¹é¢ä¼šä½¿å¾—æ¨¡å‹åœ¨æ­£å‘æ¨ç†çš„è¿‡ç¨‹ä¸­åªèƒ½å¯¹æ›´ç²—ç²’åº¦çš„è§†é¢‘ç‰‡æ®µä½œå‡ºé¢„æµ‹ã€‚</li></ol><p>å› æ­¤ï¼Œå¯¹VADè¿›è¡Œç®€å•ç›´æ¥çš„MILå»ºæ¨¡æ˜¯å­˜åœ¨é‡è¦ç¼ºé™·çš„ã€‚ä»ä»¥ä¸Šåˆ†æå¯çŸ¥ï¼ŒVADéœ€è¦è§£å†³çš„é—®é¢˜ä¸»è¦æ˜¯ï¼š</p><ol type="1"><li>æ•°æ®é›†çš„å¤§å°ï¼ˆéœ€è¦<strong>æ•°æ®å¢å¼º</strong>ï¼‰</li><li>ç¤ºä¾‹çš„<strong>è¯­ä¹‰ç¼ºå¤±</strong>ï¼ˆè§†é¢‘ç‰‡æ®µçš„<strong>é‡‡æ ·æ–¹æ³•</strong>çš„åˆç†æ€§ï¼Œè¦ä¹ˆå¢åŠ ç‰‡æ®µç‰¹å¾çš„å±€éƒ¨ä¸Šä¸‹æ–‡ä¿¡æ¯â€”â€”ä¸Šä¸‹æ–‡ä¿¡æ¯èåˆä¹Ÿå¾ˆé‡è¦ï¼‰</li><li><strong>æ± åŒ–æ“ä½œ</strong>çš„åˆç†æ€§ï¼ˆå¦‚ä½•é€‰å‡ºæœ€åˆç†çš„ä»£è¡¨ï¼Œmaxpoolingå’Œmeanpoolingä¸èƒ½æœ€æœ‰ä»£è¡¨æ€§åœ°æŒ‘é€‰å‡ºç¤ºä¾‹æˆ–<strong>ç¤ºä¾‹ç»„åˆ</strong>ï¼‰</li></ol><p>é’ˆå¯¹ä»¥ä¸Šé—®é¢˜ï¼Œè‹¥å¹²æ–‡ç« åœ¨ä¸åŒçš„æ–¹å‘ç ”ç©¶äº†æå‡VADæ€§èƒ½çš„æ–¹æ³•ã€‚è¡¨æ ¼è®°å½•åœ¨ä¸‹ä¸€ç¯‡æ–‡ç« ä¸­ã€‚</p><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><hr><ol><li id="fn1"><p>https://zhuanlan.zhihu.com/p/377220948<a href="#fnref1" class="footnote-back" role="doc-backlink">â†©ï¸</a></p></li><li id="fn2"><p>https://zhuanlan.zhihu.com/p/377220948<a href="#fnref2" class="footnote-back" role="doc-backlink">â†©ï¸</a></p></li></ol></section>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;å…³äºè§†é¢‘å¼‚å¸¸æ£€æµ‹çš„æ ¸å¿ƒé—®é¢˜&quot;&gt;å…³äºè§†é¢‘å¼‚å¸¸æ£€æµ‹çš„æ ¸å¿ƒé—®é¢˜&lt;/h3&gt;
&lt;hr&gt;
&lt;p&gt;åœ¨è¿‡å»çš„å®éªŒç ”ç©¶å½“ä¸­å‘ç°è§†é¢‘å¼‚å¸¸æ£€æµ‹çš„å…·ä½“å®ç°æœ‰å¾ˆå¤šç°å®éš¾ä»¥è§£å†³çš„é—®é¢˜ã€‚ä½†æ˜¯å¾ˆå¤šæ–‡ç« å£°ç§°çš„å…·ä½“æ–¹æ³•å´ç¼ºä¹ä»£ç å®ç°ã€‚æœ¬æ–‡å¯¹è¿‡å»çš„æ–‡çŒ®åŠ ä»¥ä»‹ç»å¹¶æ€»ç»“ï¼Œå¹¶æ·»åŠ ä¸€äº›å®éªŒä¸­å‘ç°çš„é—®é¢˜ï¼Œä»¥å¯å‘</summary>
      
    
    
    
    
  </entry>
  
</feed>
